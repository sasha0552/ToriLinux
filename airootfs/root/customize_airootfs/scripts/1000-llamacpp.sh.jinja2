#!/bin/sh
set -eu

# clone repository
git clone "{{ repositories.llamacpp }}.git"

# llama.cpp patches
pushd "llama.cpp"
  # use specific revision
  git checkout "{{ revisions.llamacpp }}"

  # create branch
  git checkout -b tori

  # TODO(remove): merge gemma fattn support fix
  git fetch origin pull/9166/head:cuda-gemma2-fattn-prec
  git merge --message "Merge branch 'cuda-gemma2-fattn-prec' into tori" --no-ff cuda-gemma2-fattn-prec
popd

# llama.cpp dependencies
pushd "llama.cpp"
  # create venv
  python3 -m venv .venv

  # activate venv
  source .venv/bin/activate
    # use pytorch for cpu
    export PIP_EXTRA_INDEX_URL="https://download.pytorch.org/whl/cpu"

    # install dependencies
    pip3 install -r requirements.txt
  deactivate
popd
