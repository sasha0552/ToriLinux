#!/bin/sh
set -eu

# clone repository
git clone "{{ repositories.llamacpp }}.git"

# llama.cpp patches
pushd "llama.cpp"
  # use specific revision
  git checkout "{{ revisions.llamacpp }}"

  # create branch
  git checkout -b tori

  # TODO(remove): merge gemma fattn support
  git fetch origin pull/8542/head:fattn-logit-softcap
  git merge --message "Merge branch 'fattn-logit-softcap' into tori" --no-ff fattn-logit-softcap

  {% if platform == "cuda" %}
  # drop pstate in idle
  patch --no-backup-if-mismatch --strip 1 < "$TORI_PATCHES/0000-llamacpp-server-drop-pstate-in-idle.patch"
  {% endif %}

  {% if platform == "cuda" %}
  # commit changes
  git add .
  git commit -m "Apply patches"
  {% endif %}
popd

# llama.cpp dependencies
pushd "llama.cpp"
  # create venv
  python3 -m venv .venv

  # activate venv
  source .venv/bin/activate
    # use pytorch for cpu
    export PIP_EXTRA_INDEX_URL="https://download.pytorch.org/whl/cpu"

    # install dependencies
    pip3 install -r requirements.txt
  deactivate
popd
