[repositories]
automatic = https://github.com/vladmandic/automatic
comfyui = https://github.com/comfyanonymous/ComfyUI
llamacpp = https://github.com/ggerganov/llama.cpp
sillytavern_extras = https://github.com/SillyTavern/SillyTavern-Extras
text_generation_webui = https://github.com/oobabooga/text-generation-webui
vllm = https://github.com/sasha0552/vllm-ci

[revisions]
automatic = d9ab46218bdbc21608a1a3465424f3fb46c954aa
comfyui = 71ec5b144ee2c46ee12f1035782d6cb4bc84cca9
llamacpp = b3030
sillytavern_extras = 1d82f3a8607319d1e09a2f4749a09c564c18c320
text_generation_webui = snapshot-2024-04-28
vllm = v0

[files]
vllm = ["triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", "vllm-0.4.2+cu124-cp311-cp311-linux_x86_64.whl"]

[strategy]
llamacpp = release
text_generation_webui = release
vllm = release+sorted

