[repositories]
automatic = https://github.com/vladmandic/automatic
comfyui = https://github.com/comfyanonymous/ComfyUI
llamacpp = https://github.com/ggerganov/llama.cpp
sillytavern_extras = https://github.com/SillyTavern/SillyTavern-Extras
text_generation_webui = https://github.com/oobabooga/text-generation-webui
vllm = https://github.com/sasha0552/vllm-ci

[revisions]
automatic = 1015dcc76bc99ecc227df369494f3f71977f4fba
comfyui = b249862080d4c046bd7f2680898c2f348c792a12
llamacpp = b3067
sillytavern_extras = 3d40acaacc4f6ea20954f1f127e3330d9c67a7ea
text_generation_webui = snapshot-2024-04-28
vllm = v1

[files]
vllm = ["triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", "vllm-0.4.3+cu124-cp311-cp311-linux_x86_64.whl"]

[strategy]
llamacpp = release
text_generation_webui = release
vllm = release+sorted

