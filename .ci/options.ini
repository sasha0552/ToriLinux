[repositories]
automatic = https://github.com/vladmandic/automatic
comfyui = https://github.com/comfyanonymous/ComfyUI
llamacpp = https://github.com/ggerganov/llama.cpp
sillytavern_extras = https://github.com/SillyTavern/SillyTavern-Extras
text_generation_webui = https://github.com/oobabooga/text-generation-webui
vllm = https://github.com/sasha0552/vllm-ci

[revisions]
automatic = e2af4542bba594e318b3b2e34e47dbe0c771e3bf
comfyui = 8508df25691b0c9213049ab0d723610d3d8f9136
llamacpp = b2961
sillytavern_extras = 1d82f3a8607319d1e09a2f4749a09c564c18c320
text_generation_webui = snapshot-2024-04-28
vllm = v0

[files]
vllm = ["triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", "vllm-0.4.2+cu124-cp311-cp311-linux_x86_64.whl"]

[strategy]
llamacpp = release
text_generation_webui = release
vllm = release+sorted

